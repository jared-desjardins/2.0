---
layout: post
title: links
description: null
img: null
---

### Guides and Introductions 
<br>

- [x] A Primer on Neural Network Models for Natural Language Processing [**pdf**](https://u.cs.biu.ac.il/~yogo/nnlp.pdf)
- [x] Machine Learning for Beginners: An Introduction to Neural Networks [**link**](https://victorzhou.com/blog/intro-to-neural-networks/)
- [x] An Introduction to Recurrent Neural Networks for Beginners [**link**](https://victorzhou.com/blog/intro-to-rnns/)
- [x] Visualizing A Neural Machine Translation Model (Seq2seq Models With Attention) [**link**](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
- [x] The Illustrated Transformer [**link**](https://jalammar.github.io/illustrated-transformer/)
- [ ] Attention Is All You Need [**pdf**](https://arxiv.org/abs/1706.03762)
- [ ] The Annotated Transformer [**link**](https://nlp.seas.harvard.edu/2018/04/03/attention.html)

<br>

### Tools and Downloads
<br>

- [ ] [**pytorch/fairseq**](https://github.com/pytorch/fairseq): Facebook AI Research sequence-to-sequence toolkit written in Python
    - [ ] [Ott et al. 2019. *FAIRSEQ: A Fast, Extensible Toolkit for Sequence Modeling*](https://arxiv.org/pdf/1904.01038.pdf)
    - [ ] [**Full Documentation**:](https://fairseq.readthedocs.io/en/latest/)
    - [ ] [**Demo**:](https://www.youtube.com/watch?v=OtgDdWtHvto&feature=emb_title)
    - [ ] [**Tutorial**:](https://www.folio3.ai/blog/fairseq/amp/)
- [ ] [**word2vec**](https://code.google.com/archive/p/word2vec/): Tool for computing continuous distributed representations of words (Google)
- [ ] [**NumPy**](https://numpy.org/): Python package for scientific computing

<br>

### Data, etc.
<br>

- [ ] [**The UniMorph Project**](https://unimorph.org/)
- [ ] [**Universal Dependencies**](https://universaldependencies.org/)
- [ ] [**Interset**](https://ufal.mff.cuni.cz/interset)
- [ ] [**Latin WordNet**](https://latinwordnet.exeter.ac.uk/)
- [ ] [**PROIEL Treebank**](https://proiel.github.io/)
- [ ] [**Word Formation Latin (WFL)^**](https://progetti.unicatt.it/progetti-milan-wfl-home)
- [ ] [**LEMLAT 3.0^**](https://www.lemlat3.eu/)
- [ ] [**Perseus Digital Library**](https://www.perseus.tufts.edu/hopper/) and [**Perseus Treebank Data**](https://github.com/PerseusDL/treebank_data)

<br>

### Papers of Interest
<br>

- [x] Silfverberg, M. & M. Hulden. 2018. *An Encoder-Decoder Approach to the Paradigm Cell Filling Problem*. [**pdf**](https://www.aclweb.org/anthology/D18-1315/)
- [x] Kirov, C. et al. 2018. *UniMorph 2.0: Universal Morphology*. [**pdf**](https://www.aclweb.org/anthology/L18-1293/)
- [x] Sylak-Glassman, J. et al. 2015. *A Language-Independent Feature Schema for Inflectional Morphology*. [**pdf**](https://www.aclweb.org/anthology/P15-2111/)
- [x] Ackerman, F. et al. 2009. *Parts and Wholes: Implicative Patterns in Inflectional Paradigms*. [**link**](https://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199547548.001.0001/acprof-9780199547548-chapter-3)
- [ ] Karttunen, L. 2003. *Computing with Realizational Morphology*. [**pdf**](https://web.stanford.edu/~laurik/publications/cicling-2003/realmorph.pdf)
- [x] Elman, J. 1990. *Finding Structure in Time*. [**pdf**](https://crl.ucsd.edu/~elman/Papers/fsit.pdf)
